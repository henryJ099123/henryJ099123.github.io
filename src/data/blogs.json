[
    {
        "id": 0,
        "urlname": "ch15",
        "name": "Chapter 15",
        "date": "7-17-25",
        "data": "# Ch. 15: Chunks of Bytecode\n\n- jlox's implementation is incredibly slow as it directly walks an AST tree\n- implicit reliance on JVM features (exceptions, `instanceof`, stack, etc.)\n    - *especially* the garbage collection\n- the AST model is *fundamentally* the wrong design; the better one is bytecode\n\n## Bytecode\n\n- alternatives to bytecode:\n\n### what about the AST?\n\n- we *have* already written it\n    -very simple to implement\n- runtime representation directly maps to the syntax\n- portable (because Java, but also in C0\n- however, not memory efficient at all\n    - every piece of syntax becomes a sea of pointers throughout memory\n    - bad for the cache too :(\n- this means we want to organize memory the way it's read\n\n### What about to native code, rather than bytecode?\n\n- This is *really* fast and best for the chip\n    - this is machine code (or assembly)\n    - yikes...I do not want to do all this in machine code\n- also no portability\n    - there are compilers like LLVM to help though\n\n### So what is bytecode?\n\n- retains portability of a tree-walker\n- sacrifices some simplicity to get a performance boost\n- structurally, bytecode looks like machine code\n    - but it's a *much* higher level instruction set than anything on a real chip\n    - ideally, the easiest possible architecture to convert to native (idealized fantasy assembly)\n- because this fantasy architecture doesn't exist, we write an *emulator*,\nwhich is a \"simulated chip\" in software, to interpret the bytecode\n    - essentially, a *virtual machine*\n    - this emulation makes it slower than going full assembly\n- so, we go from **compiler** $\\rightarrow$ **bytecode** $\\rightarrow$ **VM**\ninstead of **parser** $\\rightarrow$ **syntax tree** $\\rightarrow$ **interpreter**\n\n## Finally, getting started\n\n- just basic C files\n\n## Chunks of instructions\n\n- `chunk.c` is a module to define the bytecode representation\n- each instruction in the bytecode format has a one-byte **operation-code**\n\n### Dynamic array of instructions\n\n- why Nystrom likes dynamic arrays:\n    - Cache-friendly and dense storage\n    - Constant-time indexed element lookup\n    - Constant-time appending to end of array\n- Wow, this really is just data structures all over again\n    - add elements into the array if space\n    - if no space, must allocate a new array and copy over the elements and delete the old one\n    - **amortized analysis**: as long as the array is grown as a multiple of its current size, each append is still $O(1)$\n- array will scale by double if not there\n    - minimum threshold of 8 bytes, arbitrarily\n- `reallocate()` is a function that will take care of all dynamic memory amnagement\n- two size arguments get passed to `reallocate`:\n\n|**oldSize** | **newSize** | **Operation**|\n-------------|-------------|--------------|\n| 0 | Non-zero | Allocate a new block. |\n| Non-zero | 0 | Free allocation. |\n| Non-zero | smaller than `oldSize` | Shrink existing allocation. |\n| Non-zero | Larger than `oldSize` | Grow existing aloocation. |\n\n> What about 0 and 0?\n\n- this function is currently just a wrapper on `realloc`\n    - `realloc` is just `malloc` if `oldSize` is just 0\n    - be careful for if reallocation is possible!\n- note: we only gave in a pointer to the first byte of memory\n    - the memory allocator *under the hood* manages more information, such as the size of the memory heap block\n    - it can access this information with the pointer to the block to cleanly free it\n    - `realloc` updates this size\n    - many implementations of `malloc` store the allocated size in memory right *before* the returned address\n\n## Disassembling chunks\n\n- hard to test the code...because we are just moving bytes in memory\n- creating a **disassembler**\n    - an **assembler** takes human-readable names for CPU into binary machine code (assembly into machine code)\n    - a **disassembler** takes machine code and gives out an instruction\n    - not useful as much for Lox *users* but good for us developers\n        - mirrors the `AstPrinter` class from jlox\n- we use `disassembleChunk` to disassemble all the instructions in the chunk\n    - the other function `disassembleInstruction` disassembles each instruction in the chunk\n\n## Constants\n\n- can store *code* in chunks, but need to store *data* as well\n    - very Von Neumann\n    - no syntax tree, so we need to represent the values somehow\n\n### Representing values\n\n- use `typedef` on `double` in case we want to replace our representation of numbers in Lox with something else in C\n- for small values, instruction sets tend to store the value in the code stream immediately after the opcode, called **immediate instructions**\n    - no good for strings, so those get stored in the data section of memory for regular compilation\n    - the JVM has a **constant pool** with each compiled class\n- for Lox, we'll do that: have a \"constant pool\" for all the literals\n    - i.e. every chunk will carry a alist of all the literals it has\n    - immediates also run into problems with alignment!\n\n### Value arrays\n\n- the constant pool must be dynamic\n\n### Constant instructions\n\n- compiled data/constants needs to be *executed* as well as *stored*\n    - need to know when to produce them, so new instruction type\n- a single opcode isn't enough to know which constant to load...\n    - so, the instruction is allowed to have **operands**, which is binary data *immediately after* the opcode to parameterize the instruction\n- we need to specify the operands' format, called the **instruction format**\n    - wow, this is literally just comp arch\n- for the debugging, we print the opcode, and then the index, and then the actual value\n\n## Line information\n\n- Chunks contain almost all of the info the runtime needs from the source code\n    - we need to store the line number too, though, in case of an error\n    - in jlox, these were stored in tokens\n- given a bytecode instruction, we need to know the line of the user's source program\n    - Nystrom's simple but inefficient approach: store a separate array of integers that parallel the bytecode\n    - while very simple, it at least keeps the line information in a *separate array* from the bytecode\n        - line numbers only needed at runtime, so it shouldn't take up unneeded cache space\n- so, with these arrays, we've boiled down the family of AST trees dramatically\n\n## Design note: test your language\n\n- it's extremely important to *test* your language\n    - have a comprehensive test-suite\n- why?\n    - users expect a working programming language\n        - last thought is the compiler is bad\n    - language implementation is *very interconnected*\n    - input to a language is *combinatorial*, meaning an infinite number of programs\n    - language implementations are very complex\n- what kind of tests? often: \"language tests\", programs written in the language along with expected outputs/errors\n- why these are nice:\n    - tests aren't coupled to any internal architectural decisions\n    - can use the same tests for multiple language implementations\n    - tests can be terse and easy to read/maintain\n- why these aren't nice:\n    - end-to-end tests help determine *if* there's a bug but not where in the code\n    - crafting a good test is hard, especially for an obscure corner of the implementation\n    - overhead can be high to actually execute the tests\n\n## Notes from the exercises\n\n- did not do binary search when finding a line number in case instructions are added out of order\n- drawbacks of adding a `OP_CONSTANT_LONG` for when the number of constants exceeds 256:\n    - makes interpreter more complex\n    - uses up an opcode, which might be extremely valuable to the language if it needs them\n    - it *might* slow down the interpreter based on cache locality\n        - because new function means new code to load in\n- none of these are fatal...so not a bad idea\n"
    },
    {
        "id": 1,
        "urlname": "ch14",
        "name": "Chapter 14",
        "date": "7-17-25",
        "data": "# Ch. 14: Chunks of Bytecode\n\n- jlox's implementation is incredibly slow as it directly walks an AST tree\n- implicit reliance on JVM features (exceptions, `instanceof`, stack, etc.)\n    - *especially* the garbage collection\n- the AST model is *fundamentally* the wrong design; the better one is bytecode\n\n## Bytecode\n\n- alternatives to bytecode:\n\n### what about the AST?\n\n- we *have* already written it\n    -very simple to implement\n- runtime representation directly maps to the syntax\n- portable (because Java, but also in C0\n- however, not memory efficient at all\n    - every piece of syntax becomes a sea of pointers throughout memory\n    - bad for the cache too :(\n- this means we want to organize memory the way it's read\n\n### What about to native code, rather than bytecode?\n\n- This is *really* fast and best for the chip\n    - this is machine code (or assembly)\n    - yikes...I do not want to do all this in machine code\n- also no portability\n    - there are compilers like LLVM to help though\n\n### So what is bytecode?\n\n- retains portability of a tree-walker\n- sacrifices some simplicity to get a performance boost\n- structurally, bytecode looks like machine code\n    - but it's a *much* higher level instruction set than anything on a real chip\n    - ideally, the easiest possible architecture to convert to native (idealized fantasy assembly)\n- because this fantasy architecture doesn't exist, we write an *emulator*,\nwhich is a \"simulated chip\" in software, to interpret the bytecode\n    - essentially, a *virtual machine*\n    - this emulation makes it slower than going full assembly\n- so, we go from **compiler** $\\rightarrow$ **bytecode** $\\rightarrow$ **VM**\ninstead of **parser** $\\rightarrow$ **syntax tree** $\\rightarrow$ **interpreter**\n\n## Finally, getting started\n\n- just basic C files\n\n## Chunks of instructions\n\n- `chunk.c` is a module to define the bytecode representation\n- each instruction in the bytecode format has a one-byte **operation-code**\n\n### Dynamic array of instructions\n\n- why Nystrom likes dynamic arrays:\n    - Cache-friendly and dense storage\n    - Constant-time indexed element lookup\n    - Constant-time appending to end of array\n- Wow, this really is just data structures all over again\n    - add elements into the array if space\n    - if no space, must allocate a new array and copy over the elements and delete the old one\n    - **amortized analysis**: as long as the array is grown as a multiple of its current size, each append is still $O(1)$\n- array will scale by double if not there\n    - minimum threshold of 8 bytes, arbitrarily\n- `reallocate()` is a function that will take care of all dynamic memory amnagement\n- two size arguments get passed to `reallocate`:\n\n|**oldSize** | **newSize** | **Operation**|\n-------------|-------------|--------------|\n| 0 | Non-zero | Allocate a new block. |\n| Non-zero | 0 | Free allocation. |\n| Non-zero | smaller than `oldSize` | Shrink existing allocation. |\n| Non-zero | Larger than `oldSize` | Grow existing aloocation. |\n\n> What about 0 and 0?\n\n- this function is currently just a wrapper on `realloc`\n    - `realloc` is just `malloc` if `oldSize` is just 0\n    - be careful for if reallocation is possible!\n- note: we only gave in a pointer to the first byte of memory\n    - the memory allocator *under the hood* manages more information, such as the size of the memory heap block\n    - it can access this information with the pointer to the block to cleanly free it\n    - `realloc` updates this size\n    - many implementations of `malloc` store the allocated size in memory right *before* the returned address\n\n## Disassembling chunks\n\n- hard to test the code...because we are just moving bytes in memory\n- creating a **disassembler**\n    - an **assembler** takes human-readable names for CPU into binary machine code (assembly into machine code)\n    - a **disassembler** takes machine code and gives out an instruction\n    - not useful as much for Lox *users* but good for us developers\n        - mirrors the `AstPrinter` class from jlox\n- we use `disassembleChunk` to disassemble all the instructions in the chunk\n    - the other function `disassembleInstruction` disassembles each instruction in the chunk\n\n## Constants\n\n- can store *code* in chunks, but need to store *data* as well\n    - very Von Neumann\n    - no syntax tree, so we need to represent the values somehow\n\n### Representing values\n\n- use `typedef` on `double` in case we want to replace our representation of numbers in Lox with something else in C\n- for small values, instruction sets tend to store the value in the code stream immediately after the opcode, called **immediate instructions**\n    - no good for strings, so those get stored in the data section of memory for regular compilation\n    - the JVM has a **constant pool** with each compiled class\n- for Lox, we'll do that: have a \"constant pool\" for all the literals\n    - i.e. every chunk will carry a alist of all the literals it has\n    - immediates also run into problems with alignment!\n\n### Value arrays\n\n- the constant pool must be dynamic\n\n### Constant instructions\n\n- compiled data/constants needs to be *executed* as well as *stored*\n    - need to know when to produce them, so new instruction type\n- a single opcode isn't enough to know which constant to load...\n    - so, the instruction is allowed to have **operands**, which is binary data *immediately after* the opcode to parameterize the instruction\n- we need to specify the operands' format, called the **instruction format**\n    - wow, this is literally just comp arch\n- for the debugging, we print the opcode, and then the index, and then the actual value\n\n## Line information\n\n- Chunks contain almost all of the info the runtime needs from the source code\n    - we need to store the line number too, though, in case of an error\n    - in jlox, these were stored in tokens\n- given a bytecode instruction, we need to know the line of the user's source program\n    - Nystrom's simple but inefficient approach: store a separate array of integers that parallel the bytecode\n    - while very simple, it at least keeps the line information in a *separate array* from the bytecode\n        - line numbers only needed at runtime, so it shouldn't take up unneeded cache space\n- so, with these arrays, we've boiled down the family of AST trees dramatically\n\n## Design note: test your language\n\n- it's extremely important to *test* your language\n    - have a comprehensive test-suite\n- why?\n    - users expect a working programming language\n        - last thought is the compiler is bad\n    - language implementation is *very interconnected*\n    - input to a language is *combinatorial*, meaning an infinite number of programs\n    - language implementations are very complex\n- what kind of tests? often: \"language tests\", programs written in the language along with expected outputs/errors\n- why these are nice:\n    - tests aren't coupled to any internal architectural decisions\n    - can use the same tests for multiple language implementations\n    - tests can be terse and easy to read/maintain\n- why these aren't nice:\n    - end-to-end tests help determine *if* there's a bug but not where in the code\n    - crafting a good test is hard, especially for an obscure corner of the implementation\n    - overhead can be high to actually execute the tests\n\n## Notes from the exercises\n\n- did not do binary search when finding a line number in case instructions are added out of order\n- drawbacks of adding a `OP_CONSTANT_LONG` for when the number of constants exceeds 256:\n    - makes interpreter more complex\n    - uses up an opcode, which might be extremely valuable to the language if it needs them\n    - it *might* slow down the interpreter based on cache locality\n        - because new function means new code to load in\n- none of these are fatal...so not a bad idea\n"
    },
    {
        "id": 2,
        "urlname": "tester",
        "name": "Test File",
        "date": "Today",
        "data": "# This is a test file\n\nI'm a test file!\n\n## Here's more!\n\n*blah blah blah*\n"
    }
]